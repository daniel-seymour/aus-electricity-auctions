{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a816a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib plotly nemosis nem_bidding_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f0098b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from nemosis import static_table, dynamic_data_compiler\n",
    "import plotly.express as px\n",
    "import nem_bidding_dashboard\n",
    "\n",
    "raw_data_cache = '/Volumes/T7/NEMO_data'\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033833ec",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "Aim: Do a profit maximisation test for a single power station for a single auction\n",
    "\n",
    "RD requires bids + dispatch load. It also requires finding the supply bids for all other firms.\n",
    "MC requires bids + variable fuel costs\n",
    "\n",
    "\n",
    "NEW:\n",
    "1. As bids are on a per power station basis, adjust!\n",
    "\n",
    "OLD:\n",
    "1. Find MC estimates\n",
    "2. Group units together by the firms that control them, including the firms's daily declared capacity\n",
    "3. Create a total marginal cost function which represents the cost curve for all of a firm's generating units, stacked from lowest to highest cost. This creates a stepwise increasing function where: X-axis is cumulative MW across all units, Y-axis is marginal cost ($/MWh), each step represents a different generating unit. Width of step = unit's capacity. Height of step = unit's marginal cost\n",
    "4. Taking only units that are verified to be \"on-line\" and operating during that hour\n",
    "5. Subtracting the day-ahead scheduled quantity to center the function around 0\n",
    "6. Including only natural gas and coal units that can respond quickly (excluding nuclear, wind, hydro)\n",
    "\n",
    "#Step 1: MC estimates\n",
    "Black coal: ~$41-101/MWh\n",
    "Brown coal: ~$12-13/MWh\n",
    "Wind/Solar: $0-1/MWh\n",
    "\n",
    "Methodology:\n",
    "1. Fuel cost range: \n",
    "2. Heat rate\n",
    "3. Variable O&M (Operations and Maintenance)\n",
    "\n",
    "Note: \n",
    "1. This includes a big assumption that MC is the same across every firm for each fuel type, which is not true!\n",
    "2. For coal, it would be good to include a shutdown cost - I don't want to arbitrarily limit it like Hortaçsu as emperically coal firms are choosing to shut down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95b0f4",
   "metadata": {},
   "source": [
    "MC estimates:\n",
    "X-axis: Cumulative quantity of electricity\n",
    "Y-Axis: Price\n",
    "MC:\n",
    "Black coal: ~$41-101/MWh\n",
    "Brown coal: ~$12-13/MWh\n",
    "Natural Gas: $60-80/MWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa57321",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_estimates = {\n",
    "    \"Brown Coal\": 12.5,       # Range $12–13 => Midpoint ~12.5\n",
    "    \"Black Coal\": 71,         # Range $41–101 => Midpoint ~71\n",
    "    \"Natural Gas\": 70,        # Range $60–80 => Midpoint ~70\n",
    "    \"Kerosene\": 300,          # Range $200–400 => Midpoint ~300\n",
    "    \"Water\": 10     # Range $0–20 => Midpoint ~10\n",
    "#     \"New Large-Scale Hydro\": 95  # Range $40–150 => Midpoint ~95\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "264aef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to join DUIDs to firm names \n",
    "generator_info_df = static_table(table_name='Generators and Scheduled Loads', \n",
    "                              raw_data_location=raw_data_cache,\n",
    "                              update_static_file=False)\n",
    "generator_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ed77e",
   "metadata": {},
   "source": [
    "# Find the marginal cost function and inelastic demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c03c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the table showing what electricity has been actually dispatched\n",
    "dispatch_load_df = dynamic_data_compiler(start_time='2021/03/01 00:00:00',\n",
    "                                   end_time='2021/04/10 00:00:00',\n",
    "                                   table_name='DISPATCHLOAD',\n",
    "                                   raw_data_location=raw_data_cache)\n",
    "dispatch_load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c42f2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now merge the dispatch table with info from the Generator table\n",
    "# Perform an outer join to ensure we keep all DUIDs and settlement dates\n",
    "merged_dispatch_with_units_df = pd.merge(dispatch_load_df[['SETTLEMENTDATE', 'DUID']], generator_info_df, on=\"DUID\", how=\"outer\")\n",
    "\n",
    "# Now merge with the full dispatch_load dataset to bring all the fields together\n",
    "working_dispatch_df = pd.merge(merged_dispatch_with_units_df,dispatch_load_df, on=[\"DUID\", \"SETTLEMENTDATE\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48d99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dispatch_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f4827",
   "metadata": {},
   "source": [
    "What are the steps to filter working_dispatch_df to scale up.\n",
    "\n",
    "Preliminary:\n",
    "Remove any rows where TOTALCLEARED == 0.0 as this means no electricity was dispatched, it was a balancing action.\n",
    "\n",
    "time_date_company\n",
    "Time is fixed and then a nested loop is needed to go through the different dates and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06024707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(working_dispatch_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de8bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dispatch_df['TOTALCLEARED'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54fbb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dispatch_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ace62247",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dispatch_df_filtered = working_dispatch_df[working_dispatch_df['TOTALCLEARED'].notna() & (working_dispatch_df['TOTALCLEARED'] != 0.0)]\n",
    "working_dispatch_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad2f1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now filter again just for the dispatch loads of Origin Energy electricity plants for the 6:00-6:05pm auction\n",
    "dispatch_df_time = working_dispatch_df_filtered[\n",
    "    working_dispatch_df_filtered[\"SETTLEMENTDATE\"].astype(str).str.contains(\"18:05:00\", na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c965f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2021-04-07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98426749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for a single day\n",
    "# Next step: create a for loop to go through each of the dates\n",
    "dispatch_df_time_date = dispatch_df_time[dispatch_df_time['SETTLEMENTDATE'].astype(str).str.contains(date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee8680",
   "metadata": {},
   "source": [
    "## What is inelastic demand for this 5 minute auction on this day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a678e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inelastic_demand = dispatch_df_time_date['TOTALCLEARED'].sum()\n",
    "inelastic_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb7617d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_i = \"Origin Energy Electricity Limited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "167e1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 'Origin Energy Electricity Limited' as it's the company with the largest number of power stations\n",
    "# We join the dispatch_units and the dispatch_load tables on DUID\n",
    "dispatch_df_time_date_company = dispatch_df_time_date[dispatch_df_time_date[\"Participant\"] == firm_i]\n",
    "\n",
    "dispatch_df_time_date_company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef603d4",
   "metadata": {},
   "source": [
    "## Find the Marginal Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cee6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_df_time_date_company.loc[:, \"AU$/MWh\"] = (\n",
    "    dispatch_df_time_date_company[\"Fuel Source - Descriptor\"].map(cost_estimates)\n",
    ")\n",
    "\n",
    "dispatch_df_time_date_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4691c1fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorting by MC per MW/h as a firm would dispatch their lowest cost power stations first\n",
    "dispatch_df_time_date_company = dispatch_df_time_date_company.sort_values(\"AU$/MWh\")\n",
    "dispatch_df_time_date_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da9e521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dispatch_df_time_date_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "307518e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is firm i's capacity for this 5 minute auction on this day?\n",
    "total_avail = dispatch_df_time_date_company['AVAILABILITY'].sum()\n",
    "total_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e32d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cumulative capacity using the 'MAXAVAIL_x' column\n",
    "dispatch_df_time_date_company['CumulativeCapacity'] = dispatch_df_time_date_company['AVAILABILITY'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7aa0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_df_time_date_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68b3a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Marginal Cost curve for firm i\n",
    "\n",
    "# 3. Plot the stepwise MC (price) function\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the step function (supply curve)\n",
    "plt.step(\n",
    "    dispatch_df_time_date_company['CumulativeCapacity'],\n",
    "    dispatch_df_time_date_company['AU$/MWh'],\n",
    "    where='post',\n",
    "    label=\"MC Supply Curve\"\n",
    ")\n",
    "\n",
    "# 4. Overlay cross markers for each data point\n",
    "plt.plot(\n",
    "    dispatch_df_time_date_company['CumulativeCapacity'],\n",
    "    dispatch_df_time_date_company['AU$/MWh'],\n",
    "    linestyle=\"None\",   # no line, only markers\n",
    "    marker=\"x\",         # cross markers\n",
    "    color=\"red\",\n",
    "    label=\"Data Points\"\n",
    ")\n",
    "\n",
    "# 5. Label the axes\n",
    "plt.xlabel(\"Quantity (MW)\")\n",
    "plt.ylabel(\"Price (AU$/MWh)\")\n",
    "plt.title(f\"Marginal Cost Function for {firm_i} on {date}\")\n",
    "\n",
    "# Add a legend and grid for clarity\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5c8b8",
   "metadata": {},
   "source": [
    "# Find the Supply Bid Function\n",
    "\n",
    "Preliminary:\n",
    "Remove any rows which are not energy actions as these are bids for the separate balancing market.\n",
    "\n",
    "As with filtering the dispatch_df, we will follow the hierarchial structure of time_date_company\n",
    "Time is fixed and then a nested loop is needed to go through the different dates and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4076cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to find the supply bids to work out residual demand and the actual supply bid function\n",
    "volume_bids = dynamic_data_compiler(start_time='2021/03/01 00:00:00',\n",
    "                                   end_time='2021/04/10 00:00:00',\n",
    "                                   table_name='BIDPEROFFER_D',\n",
    "                                   raw_data_location=raw_data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fbf11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the dispatch_units and the dispatch_load tables on DUID\n",
    "\n",
    "# Perform an outer join to ensure we keep all DUIDs and settlement dates\n",
    "merged_bids_with_units_df = pd.merge(volume_bids, generator_info_df, on=\"DUID\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4874960",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_merged_bids_with_units_df  = merged_bids_with_units_df[merged_bids_with_units_df['BIDTYPE'] == 'ENERGY']\n",
    "filtered_merged_bids_with_units_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23ee51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only the 6-6:05pm auctions\n",
    "# Here we look at the interval at 6pm because this is the start of the auction where the bids apply\n",
    "bids_time_df = filtered_merged_bids_with_units_df[\n",
    "    filtered_merged_bids_with_units_df[\"INTERVAL_DATETIME\"].astype(str).str.contains(\"18:00:00\", na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e58ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the single day we're looking at '2021-04-07'\n",
    "# Eventually need to wrap this in a loop across all days\n",
    "\n",
    "target_date = pd.to_datetime(date)\n",
    "volume_bids_time_date_df = bids_time_df[bids_time_df['SETTLEMENTDATE'].dt.date == target_date.date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc8fea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_bids_time_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ab95235",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_bids_time_date_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e49988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the number of DUIDS\n",
    "# We need to first aggregate into the same market participants (firms)\n",
    "# And then find the residual demand from each residual bid\n",
    "unique_DUIDs = volume_bids_time_date_df[\"DUID\"].unique()\n",
    "len(unique_DUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "551e6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_participants = volume_bids_time_date_df[\"Participant\"].unique()\n",
    "len(unique_participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93404ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter for 'Origin Energy Electricity Limited'\n",
    "# filtered_bids_df = bids_with_duid[bids_with_duid[\"Participant\"] == \"Origin Energy Electricity Limited\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c80b6",
   "metadata": {},
   "source": [
    "What is the strategy for price bids?\n",
    "Important to recall that price bids only change once a day\n",
    "We need to match the price bands ups with volume bids based on the DUID\n",
    "Can I just do this in one go per day?\n",
    "\n",
    "Filtering:\n",
    "Remove any bids that are not 'ENERGY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3e6b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the price bids.\n",
    "price_bids_df = dynamic_data_compiler(start_time='2021/03/01 00:00:00',\n",
    "                                   end_time='2021/04/10 00:00:00',\n",
    "                                   table_name='BIDDAYOFFER_D',\n",
    "                                   raw_data_location=raw_data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ce07cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bids_filtered_df = price_bids_df[price_bids_df['BIDTYPE'] == 'ENERGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fe0386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bids_day_df = price_bids_filtered_df[price_bids_filtered_df['SETTLEMENTDATE'] == '2021-04-07']\n",
    "price_bids_day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c18a111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_volume_and_price_bids_df = pd.merge(price_bids_day_df, volume_bids_time_date_df, on=[\"DUID\", \"SETTLEMENTDATE\"])\n",
    "merged_volume_and_price_bids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "293f11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove where max avail is zero because these are placeholder bids\n",
    "# Where the generator is not able to produce\n",
    "merged_volume_and_price_bids_filtered_df = merged_volume_and_price_bids_df[merged_volume_and_price_bids_df[\"MAXAVAIL\"] != 0]\n",
    "merged_volume_and_price_bids_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2124d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the maximum Megawatts that are able to be produced in this auction\n",
    "# if all generators generated at peak capacity\n",
    "max_avail = merged_volume_and_price_bids_filtered_df['MAXAVAIL'].sum()\n",
    "max_avail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff3ad1",
   "metadata": {},
   "source": [
    "There is a modification required because the total capacity that firms bid is often higher than the max capacity of the generator. This is because the max capacity takes priority and the auctioneer caps firms at their submitted max capacity. This means firms are able to bid whatever volumes in the knowledge they won't be called to produce more than their actual max capacity. \n",
    "\n",
    "We will have the columns:\n",
    "MAXAVAIL: Hard limit\n",
    "TOTAL_BANDAVAIL: Total volume bid\n",
    "SUM_OF_BANDAVAIL: The capped volume bid so that what firms bid matches the hard limit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29dc4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the band availability columns\n",
    "bandavail_cols = [f\"BANDAVAIL{i}\" for i in range(1, 11)]  # BANDAVAIL1 to BANDAVAIL10\n",
    "\n",
    "# 2. Create a new column summing them correctly with .loc to avoid SettingWithCopyWarning\n",
    "merged_volume_and_price_bids_filtered_df = merged_volume_and_price_bids_filtered_df.copy()  # Ensure we are working on a copy\n",
    "merged_volume_and_price_bids_filtered_df.loc[:, \"TOTAL_BANDAVAIL\"] = merged_volume_and_price_bids_filtered_df[bandavail_cols].sum(axis=1)\n",
    "\n",
    "# 3. Remove rows where TOTAL_BANDAVAIL is 0\n",
    "no_zeroes_combined_bids_df = merged_volume_and_price_bids_filtered_df[merged_volume_and_price_bids_filtered_df[\"TOTAL_BANDAVAIL\"] != 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a08380cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each row in the group (same DUID & SETTLEMENTDATE):\n",
    "  1) Sort the 10 band pairs by ascending price.\n",
    "  2) Accumulate volumes, stopping at MAXAVAIL.\n",
    "  3) Partially fill the band where we hit the limit.\n",
    "  4) Set subsequent bands to zero.\n",
    "  5) Write the modified band volumes back in the original wide order.\n",
    "\"\"\"\n",
    "    \n",
    "def cap_bands_in_wide_mode(group):\n",
    "\n",
    "    # We'll modify each row separately\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        \n",
    "        # Extract max_avail for this row\n",
    "        max_avail = row[\"MAXAVAIL\"]\n",
    "        \n",
    "        # Gather the 10 band pairs: (price, volume, band_index)\n",
    "        # E.g., (PRICEBAND1, BANDAVAIL1, index=1), etc.\n",
    "        band_info = []\n",
    "        for i in range(1, 11):\n",
    "            price_col = f\"PRICEBAND{i}\"\n",
    "            vol_col   = f\"BANDAVAIL{i}\"\n",
    "            \n",
    "            price_val = row[price_col]\n",
    "            vol_val   = row[vol_col]\n",
    "            \n",
    "            band_info.append((price_val, vol_val, i))\n",
    "        \n",
    "        # Sort by ascending price\n",
    "        band_info.sort(key=lambda x: x[0] if not pd.isna(x[0]) else np.inf)\n",
    "        \n",
    "        # Accumulate volumes, capping at max_avail\n",
    "        running_sum = 0.0\n",
    "        capped_bands = []\n",
    "        \n",
    "        for (price, volume, idx) in band_info:\n",
    "            if pd.isna(volume): \n",
    "                # If volume is NaN, treat it as 0\n",
    "                volume = 0.0\n",
    "            \n",
    "            if running_sum >= max_avail:\n",
    "                # Already at or beyond limit\n",
    "                capped_bands.append((price, 0.0, idx))\n",
    "            else:\n",
    "                potential = running_sum + volume\n",
    "                if potential <= max_avail:\n",
    "                    # Can use full band\n",
    "                    capped_bands.append((price, volume, idx))\n",
    "                    running_sum += volume\n",
    "                else:\n",
    "                    # Partially use this band\n",
    "                    remainder = max_avail - running_sum\n",
    "                    capped_bands.append((price, remainder, idx))\n",
    "                    running_sum += remainder\n",
    "        \n",
    "        # Now re-sort by the original band index so we can put them back into the row\n",
    "        capped_bands.sort(key=lambda x: x[2])\n",
    "        \n",
    "        # Write them back into the row's band columns\n",
    "        row_capped = row.copy()  # copy original\n",
    "        for (price, cap_vol, idx) in capped_bands:\n",
    "            vol_col = f\"BANDAVAIL{idx}\"\n",
    "            row_capped[vol_col] = cap_vol\n",
    "        \n",
    "        new_rows.append(row_capped)\n",
    "    \n",
    "    # Return the modified rows as a DataFrame\n",
    "    return pd.DataFrame(new_rows)\n",
    "\n",
    "capped_combined_bids_df = (\n",
    "    no_zeroes_combined_bids_df\n",
    "    .groupby([\"DUID\", \"SETTLEMENTDATE\"], group_keys=False)\n",
    "    .apply(cap_bands_in_wide_mode)\n",
    ")\n",
    "\n",
    "capped_combined_bids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36023768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns for melting\n",
    "price_columns = [f\"PRICEBAND{i}\" for i in range(1, 11)]\n",
    "volume_columns = [f\"BANDAVAIL{i}\" for i in range(1, 11)]\n",
    "\n",
    "# Include the additional columns you want to keep in long format\n",
    "id_vars_cols = [\n",
    "    \"DUID\",\n",
    "    \"SETTLEMENTDATE\",\n",
    "    \"Participant\",\n",
    "    \"Station Name\",\n",
    "    \"Fuel Source - Descriptor\"\n",
    "]\n",
    "\n",
    "# Melt price bands into long format\n",
    "melted_prices = (\n",
    "    capped_combined_bids_df\n",
    "    .melt(\n",
    "        id_vars=id_vars_cols,             # <--- Add your additional columns here\n",
    "        value_vars=price_columns,\n",
    "        var_name=\"PRICE_BAND\",\n",
    "        value_name=\"PRICE\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Melt volume bands into long format\n",
    "melted_volumes = (\n",
    "    capped_combined_bids_df\n",
    "    .melt(\n",
    "        id_vars=id_vars_cols,             # <--- Same additional columns\n",
    "        value_vars=volume_columns,\n",
    "        var_name=\"VOLUME_BAND\",\n",
    "        value_name=\"VOLUME\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Extract the band number (1..10) from PRICE_BAND or VOLUME_BAND\n",
    "melted_prices[\"BAND_NUMBER\"] = melted_prices[\"PRICE_BAND\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "melted_volumes[\"BAND_NUMBER\"] = melted_volumes[\"VOLUME_BAND\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Merge long-format prices and volumes on DUID, SETTLEMENTDATE, and BAND_NUMBER\n",
    "bid_curve_df = pd.merge(\n",
    "    melted_prices,\n",
    "    melted_volumes,\n",
    "    on=[\"DUID\", \"SETTLEMENTDATE\", \"Participant\", \"Station Name\", \"Fuel Source - Descriptor\", \"BAND_NUMBER\"]\n",
    ")\n",
    "\n",
    "# View the merged DataFrame\n",
    "bid_curve_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4262e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_curve_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b58e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_curve_df = bid_curve_df.sort_values(by=[\"DUID\", \"SETTLEMENTDATE\", \"PRICE\"])\n",
    "bid_curve_df[\"CUMULATIVE_VOLUME\"] = bid_curve_df.groupby([\"DUID\", \"SETTLEMENTDATE\"])[\"VOLUME\"].cumsum()\n",
    "with pd.option_context('display.max_rows', None, \n",
    "                      'display.max_columns', None,\n",
    "                      'display.width', None,\n",
    "                      'display.max_colwidth', None):\n",
    "    display(bid_curve_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0412762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This aggregates volumes by (Participant, SETTLEMENTDATE, PRICE)\n",
    "# meaning that we can construct a firm-wide aggregate supply function \n",
    "# which has multiple DUIDs\n",
    "\n",
    "firm_aggregated_bids = (\n",
    "    bid_curve_df\n",
    "    .groupby([\"Participant\", \"SETTLEMENTDATE\", \"PRICE\"], as_index=False)[\"VOLUME\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# 2) Sort so we can build a piecewise curve in ascending PRICE order\n",
    "firm_aggregated_bids = firm_aggregated_bids.sort_values([\"Participant\", \"SETTLEMENTDATE\", \"PRICE\"])\n",
    "\n",
    "firm_aggregated_bids[\"FIRM_CUMULATIVE_VOLUME\"] = (\n",
    "    aggregated_bids\n",
    "    .groupby([\"Participant\", \"SETTLEMENTDATE\"])[\"VOLUME\"]\n",
    "    .cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "faa83c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_aggregated_bids[\"TOTAL_CUMULATIVE_VOLUME\"] = firm_aggregated_bids.groupby(\"SETTLEMENTDATE\")[\"VOLUME\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf853723",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_aggregated_bids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebfc56",
   "metadata": {},
   "source": [
    "## Finding the residual demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b84b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_i_df = firm_aggregated_bids[firm_aggregated_bids[\"Participant\"] == firm_i]\n",
    "firm_i_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a494c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot firm i's supply bid function\n",
    "\n",
    "plt.step(firm_i_df[\"FIRM_CUMULATIVE_VOLUME\"], firm_i_df[\"PRICE\"], where='post')\n",
    "plt.xlabel(\"Cumulative Volume (MW)\")\n",
    "plt.ylabel(\"Price ($/MWh)\")\n",
    "plt.title(f\"Supply Bid Function of {firm_i} on {date}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0997bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rival_firms_df = aggregated_bids[aggregated_bids[\"Participant\"] != firm_i].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "264aff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rival_firms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f79da885",
   "metadata": {},
   "outputs": [],
   "source": [
    "rival_grouped_df = (\n",
    "    rival_firms_df\n",
    "    .groupby([\"SETTLEMENTDATE\", \"PRICE\"], as_index=False)[\"VOLUME\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"VOLUME\": \"RIVAL_VOLUME\"})  # rename for clarity\n",
    ")\n",
    "\n",
    "# Compute stepwise cumulative supply for each date\n",
    "rival_grouped_df[\"CUMULATIVE_RIVAL_SUPPLY\"] = (\n",
    "    rival_grouped_df\n",
    "    .groupby(\"SETTLEMENTDATE\")[\"RIVAL_VOLUME\"]\n",
    "    .cumsum()\n",
    ")\n",
    "\n",
    "rival_grouped_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8f34001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have already found the inelastic demand by summing the total cleared in dispatch\n",
    "inelastic_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7fd0ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rival_grouped_df[\"RESIDUAL_DEMAND\"] = (\n",
    "    inelastic_demand \n",
    "    - rival_grouped_df[\"CUMULATIVE_RIVAL_SUPPLY\"]\n",
    ")\n",
    "\n",
    "rival_grouped_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6042134",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.step(\n",
    "    rival_grouped_df[\"RESIDUAL_DEMAND\"],  # X-axis\n",
    "    rival_grouped_df[\"PRICE\"],           # Y-axis\n",
    "    where='post'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Residual Demand (MW)\")\n",
    "plt.ylabel(\"Price ($/MWh)\")\n",
    "plt.title(\"Residual Demand Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9341f",
   "metadata": {},
   "source": [
    "## Plotting firm i's supply bid function, firm i's residual demand, and the marginal cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2cdcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 1. Plot the Residual Demand Curve (step plot)\n",
    "plt.step(\n",
    "    rival_grouped_df[\"RESIDUAL_DEMAND\"],  # X-axis for residual demand\n",
    "    rival_grouped_df[\"PRICE\"],            # Y-axis for residual demand\n",
    "    where='post',\n",
    "    label=\"Residual Demand Curve\"\n",
    ")\n",
    "\n",
    "# 2. Plot firm i's Supply Bid Function (step plot)\n",
    "plt.step(\n",
    "    firm_i_df[\"FIRM_CUMULATIVE_VOLUME\"],  # X-axis for supply bid\n",
    "    firm_i_df[\"PRICE\"],                   # Y-axis for supply bid\n",
    "    where='post',\n",
    "    label=f\"Supply Bid Function of {firm_i}\"\n",
    ")\n",
    "\n",
    "# 3. Plot the MC Supply Curve (step plot) with data points\n",
    "plt.step(\n",
    "    dispatch_df_time_date_company['CumulativeCapacity'], \n",
    "    dispatch_df_time_date_company['AU$/MWh'], \n",
    "    where='post',\n",
    "    label=\"MC Supply Curve\"\n",
    ")\n",
    "plt.plot(\n",
    "    dispatch_df_time_date_company['CumulativeCapacity'], \n",
    "    dispatch_df_time_date_company['AU$/MWh'],\n",
    "    linestyle=\"None\",   # No connecting lines, only markers\n",
    "    marker=\"x\",\n",
    "    color=\"red\",\n",
    "    label=\"MC Data Points\"\n",
    ")\n",
    "\n",
    "# Label the axes and title\n",
    "plt.xlabel(\"Quantity (MW)\")\n",
    "plt.ylabel(\"Price ($/MWh)\")  # Adjust the units if necessary\n",
    "plt.title(f\"Combined Market Curves for {firm_i} on {date}\")\n",
    "\n",
    "# Add legend and grid\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4f82f",
   "metadata": {},
   "source": [
    "## A test is to intersect the inelastic demand and the overall market supply function\n",
    "I believe the above graph is currently wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d6b128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_aggregated_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d2aeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the needed columns\n",
    "df = firm_aggregated_bids[[\"SETTLEMENTDATE\", \"PRICE\", \"VOLUME\"]].copy()\n",
    "\n",
    "# Sort by SETTLEMENTDATE and PRICE (ascending order)\n",
    "df = df.sort_values([\"SETTLEMENTDATE\", \"PRICE\"], ascending=[True, True])\n",
    "\n",
    "df = df[df[\"VOLUME\"] != 0]\n",
    "\n",
    "# Recalculate cumulative volume for each date\n",
    "df[\"CUMULATIVE_VOLUME\"] = df.groupby(\"SETTLEMENTDATE\")[\"VOLUME\"].cumsum()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "display(df)  # or simply: df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "152a1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first row where the cumulative volume meets or exceeds the inelastic demand\n",
    "try:\n",
    "    mc_row = df[df[\"CUMULATIVE_VOLUME\"] >= inelastic_demand].iloc[0]\n",
    "    market_clearing_price = mc_row[\"PRICE\"]\n",
    "    print(\"Market Clearing Price:\", market_clearing_price)\n",
    "except IndexError:\n",
    "    print(\"Inelastic demand exceeds the total cumulative volume. Check your data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4233780",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_row = df[df[\"PRICE\"] == -34.99]\n",
    "print(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbd2b22e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 2. Create the Plot:\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot the aggregated supply curve as a step function:\n",
    "# plt.step(\n",
    "#     firm_aggregated_bids[\"TOTAL_CUMULATIVE_VOLUME\"],  # X-axis: cumulative volume\n",
    "#     firm_aggregated_bids[\"PRICE\"],                      # Y-axis: bid price\n",
    "#     where='post',\n",
    "#     label=\"Supply Curve\"\n",
    "# )\n",
    "\n",
    "# # Plot the inelastic demand line (vertical line):\n",
    "# plt.axvline(\n",
    "#     x=inelastic_demand, \n",
    "#     color=\"red\", \n",
    "#     linestyle=\"--\", \n",
    "#     label=\"Inelastic Demand\"\n",
    "# )\n",
    "\n",
    "# # Mark the intersection (market clearing point) with a marker:\n",
    "# plt.scatter(\n",
    "#     [inelastic_demand], \n",
    "#     [market_clearing_price], \n",
    "#     color=\"green\", \n",
    "#     zorder=5, \n",
    "#     label=f\"Market Clearing Price: {market_clearing_price:.2f}\"\n",
    "# )\n",
    "\n",
    "# # Label the axes and add a title:\n",
    "# plt.xlabel(\"Cumulative Volume (MW)\")\n",
    "# plt.ylabel(\"Price ($/MWh)\")\n",
    "# plt.title(\"Market Clearing: Intersection of Supply Curve and Inelastic Demand\")\n",
    "\n",
    "# # Add a legend and grid for clarity:\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426fc4a",
   "metadata": {},
   "source": [
    "## What do I notice\n",
    "Need to truncate the residual demand to what is the capacity of firm i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8fec3b",
   "metadata": {},
   "source": [
    "## Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2554829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the price bids.\n",
    "price_data = dynamic_data_compiler(start_time='2021/03/01 00:00:00',\n",
    "                                   end_time='2021/04/10 00:00:00',\n",
    "                                   table_name='DISPATCHPRICE',\n",
    "                                   raw_data_location=raw_data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdbc09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f5060da",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4836d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = price_data[price_data['SETTLEMENTDATE'] == '2021-04-07 18:05:00']\n",
    "test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614dcc72",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "\n",
    "Hypothesis: Pricing and dispatch is done on a regional basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70362c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nem_bidding_dashboard import fetch_data\n",
    "from nem_bidding_dashboard import fetch_and_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7223a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_bids = fetch_data.volume_bids(\n",
    "    start_time='2022/01/01 00:00:00',\n",
    "    end_time='2022/01/01 00:05:00',\n",
    "    raw_data_cache=raw_data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fbb1dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids = fetch_and_preprocess.bid_data(\n",
    "    start_time='2021/04/07 18:00:00',\n",
    "    end_time='2021/04/07 18:05:00',\n",
    "    raw_data_cache=raw_data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a55936c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d893b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db299a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inelastic demand already defined\n",
    "\n",
    "bids_sorted = bids.sort_values(by=\"BIDPRICE\", ascending=True) \n",
    "\n",
    "# Calculate cumulative sum of BIDVOLUMEADJUSTED for each settlement interval\n",
    "bids_sorted['cum_bidvolumeadjusted'] = bids_sorted.groupby('INTERVAL_DATETIME')['BIDVOLUMEADJUSTED'].cumsum()\n",
    "\n",
    "# Create the demand_function column as the inelastic demand minus the cumulative bid volume adjusted\n",
    "bids_sorted['demand_function'] = inelastic_demand - bids_sorted['cum_bidvolumeadjusted']\n",
    "\n",
    "bids_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b970eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all bids for the 6:00-6:05pm interval\n",
    "# INTERVAL_DATETIME in the bids data indicates the start of the 5-minute interval that the bids apply to\n",
    "# We need to take the total demand and minus all the other rival bids. \n",
    "# If this is happening at a firm level, then that needs to be automated before moving on \n",
    "# so we need to find all the firm's supply bids or just do \n",
    "\n",
    "all_bids_for_single_day_auction = bids_with_duid[bids_with_duid['INTERVAL_DATETIME']  == '2021-04-09 18:00:00'] \n",
    "all_bids_for_single_day_auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995f294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
